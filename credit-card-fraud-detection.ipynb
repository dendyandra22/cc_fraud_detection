{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Credit Card Fraud Detection","metadata":{}},{"cell_type":"markdown","source":"# Load Dataset","metadata":{}},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:54:02.545795Z","iopub.execute_input":"2023-05-08T08:54:02.546872Z","iopub.status.idle":"2023-05-08T08:54:02.558592Z","shell.execute_reply.started":"2023-05-08T08:54:02.546835Z","shell.execute_reply":"2023-05-08T08:54:02.557205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_df = pd.read_csv('/kaggle/input/fraud-detection/creditcard.csv')\n# raw_df.head()\n\n# raw_df = pd.read_csv('./creditcard.csv')\nraw_df.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:54:02.565536Z","iopub.execute_input":"2023-05-08T08:54:02.566197Z","iopub.status.idle":"2023-05-08T08:54:05.478304Z","shell.execute_reply.started":"2023-05-08T08:54:02.566149Z","shell.execute_reply":"2023-05-08T08:54:05.477102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis (EDA)","metadata":{}},{"cell_type":"code","source":"raw_df.describe().T","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:54:05.480152Z","iopub.execute_input":"2023-05-08T08:54:05.480603Z","iopub.status.idle":"2023-05-08T08:54:05.980110Z","shell.execute_reply.started":"2023-05-08T08:54:05.480562Z","shell.execute_reply":"2023-05-08T08:54:05.978267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:54:05.987016Z","iopub.execute_input":"2023-05-08T08:54:05.992565Z","iopub.status.idle":"2023-05-08T08:54:06.020614Z","shell.execute_reply.started":"2023-05-08T08:54:05.992496Z","shell.execute_reply":"2023-05-08T08:54:06.019007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Distribution","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:54:06.022488Z","iopub.execute_input":"2023-05-08T08:54:06.022944Z","iopub.status.idle":"2023-05-08T08:54:06.650398Z","shell.execute_reply.started":"2023-05-08T08:54:06.022901Z","shell.execute_reply":"2023-05-08T08:54:06.649250Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_df.hist(figsize=(16,12))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:54:06.652247Z","iopub.execute_input":"2023-05-08T08:54:06.652678Z","iopub.status.idle":"2023-05-08T08:54:10.533591Z","shell.execute_reply.started":"2023-05-08T08:54:06.652636Z","shell.execute_reply":"2023-05-08T08:54:10.532158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# numeric_columns = (list(raw_df.loc[:, ['Time','Amount']]))\n\n# fig = plt.figure(figsize=(20, 50))\n# rows, cols = 10, 3\n# for idx, num in enumerate(numeric_columns[:30]):\n#     ax = fig.add_subplot(rows, cols, idx+1)\n#     ax.grid(alpha = 0.7, axis =\"both\")\n#     sns.kdeplot(x = num, fill = True,color =\"#3386FF\",linewidth=0.6, data = raw_df)\n#     ax.legend()\n# fig.tight_layout()\n# fig.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:54:10.535202Z","iopub.execute_input":"2023-05-08T08:54:10.535633Z","iopub.status.idle":"2023-05-08T08:54:10.540949Z","shell.execute_reply.started":"2023-05-08T08:54:10.535592Z","shell.execute_reply":"2023-05-08T08:54:10.539920Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Genuine vs Fraud Comparation","metadata":{}},{"cell_type":"code","source":"tmp = raw_df.Class.value_counts()\npie_val = [tmp[0] / sum(tmp) * 100, tmp[1] / sum(tmp) * 100]\nplt.figure(figsize=(12,6))\nplt.subplot(1,2,1)\nplt.pie(pie_val,labels = ['Genuine','Fraud'], \n        autopct = '%1.2f%%',\n        startangle = 90,\n        explode = (0.1,0.1),\n        colors = ['#66b3ff','#ffcc99'], \n        wedgeprops = {'linewidth': 1, 'antialiased' : True})\nplt.title('Genuine vs Fraud Transaction Percentage')\n\nplt.subplot(1,2,2)\nax = sns.countplot(data = raw_df, \n                   x='Class', \n                   palette = ['#66b3ff','#ffcc99']\n                   )\nfor i in ax.containers:\n    ax.bar_label(i,)\nax.set_xticklabels(['Genuine','Fraud'])\n    \nplt.title('Genuine and Fraud Transaction Comparation')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:54:10.542447Z","iopub.execute_input":"2023-05-08T08:54:10.543389Z","iopub.status.idle":"2023-05-08T08:54:10.905804Z","shell.execute_reply.started":"2023-05-08T08:54:10.543346Z","shell.execute_reply":"2023-05-08T08:54:10.904481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,12))\n\ntmp = {}\nfor i, data in enumerate(raw_df.groupby('Class')['Amount'].median()):\n    tmp[i] = data\n\nplt.subplot(2,2,1)\nax = sns.barplot(x=list(tmp.keys()),\n                 y=[float(tmp[k]) for k in tmp.keys()],\n                 palette=['#66b3ff','#ffcc99'])\nfor i in ax.containers:\n    ax.bar_label(i,)\nax.set_xticklabels(['Genuine','Fraud'])\nax.set_title('Genuine vs Fraud Amount Median')\n\ntmp = {}\nfor i, data in enumerate(raw_df.groupby('Class')['Amount'].mean()):\n    tmp[i] = data\n\nplt.subplot(2,2,2)\nax = sns.barplot(x=list(tmp.keys()),\n                 y=[float(tmp[k]) for k in tmp.keys()],\n                 palette=['#66b3ff','#ffcc99'])\nfor i in ax.containers:\n    ax.bar_label(i,)\nax.set_xticklabels(['Genuine','Fraud'])\nax.set_title('Genuine vs Fraud Amount Mean')\n\nplt.subplot(2,2,3)\nax = sns.barplot(x=list(tmp.keys()),\n                 y=[float(tmp[k]) for k in tmp.keys()],\n                 palette=['#66b3ff','#ffcc99'])\nfor i in ax.containers:\n    ax.bar_label(i,)\nax.set_xticklabels(['Genuine','Fraud'])\nax.set_title('Genuine vs Fraud Time Median')\n\ntmp = {}\nfor i, data in enumerate(raw_df.groupby('Class')['Time'].mean()):\n    tmp[i] = data\n\nplt.subplot(2,2,4)\nax = sns.barplot(x=list(tmp.keys()),\n                 y=[float(tmp[k]) for k in tmp.keys()],\n                 palette=['#66b3ff','#ffcc99'])\nfor i in ax.containers:\n    ax.bar_label(i,)\nax.set_xticklabels(['Genuine','Fraud'])\nax.set_title('Genuine vs Fraud Time Mean')","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:54:10.907362Z","iopub.execute_input":"2023-05-08T08:54:10.907725Z","iopub.status.idle":"2023-05-08T08:54:11.677686Z","shell.execute_reply.started":"2023-05-08T08:54:10.907693Z","shell.execute_reply":"2023-05-08T08:54:11.676475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Both Amount and Time have very significant mean and median differences due to influence of outliers","metadata":{}},{"cell_type":"markdown","source":"### Feature Correlation","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.heatmap(raw_df.drop('Class', axis=1).corr(), cmap='magma')","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:54:11.679394Z","iopub.execute_input":"2023-05-08T08:54:11.679971Z","iopub.status.idle":"2023-05-08T08:54:13.178379Z","shell.execute_reply.started":"2023-05-08T08:54:11.679931Z","shell.execute_reply":"2023-05-08T08:54:13.177039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Amount and Time have a weak to moderate correlation with some of the features in the data set.","metadata":{}},{"cell_type":"markdown","source":"### Checking Outlier Data","metadata":{}},{"cell_type":"code","source":"# select only numeric features\nnumeric_features = (list(raw_df.loc[:, 'V1':'Amount'])) \n\n# checking boxplots\ndef boxplots_custom(dataset, columns_list, rows, cols, suptitle):\n    fig, axs = plt.subplots(rows, cols, sharey=True, figsize=(16,25))\n    fig.suptitle(suptitle,y=1, size=25)\n    axs = axs.flatten()\n    for i, data in enumerate(columns_list):\n        sns.boxplot(data=dataset[data], orient='h', ax=axs[i])\n        axs[i].set_title(data + ', skewness is: '+str(round(dataset[data].skew(axis = 0, skipna = True),2)))\n        \nboxplots_custom(dataset=raw_df, columns_list=numeric_features, rows=10, cols=3, suptitle='Boxplots for each variable')\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:54:13.180326Z","iopub.execute_input":"2023-05-08T08:54:13.180754Z","iopub.status.idle":"2023-05-08T08:54:19.386500Z","shell.execute_reply.started":"2023-05-08T08:54:13.180715Z","shell.execute_reply":"2023-05-08T08:54:19.385242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"there is a lot of outlier from each features, now try to remove it using Inter Quartile Range (IQR) method ","metadata":{}},{"cell_type":"markdown","source":"#### Removing Outlier with IQR","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom collections import Counter","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:54:19.388262Z","iopub.execute_input":"2023-05-08T08:54:19.388761Z","iopub.status.idle":"2023-05-08T08:54:19.394362Z","shell.execute_reply.started":"2023-05-08T08:54:19.388715Z","shell.execute_reply":"2023-05-08T08:54:19.393322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def IQR_method (df,min_outliers,features):\n    \"\"\"\n    Takes a dataframe and returns an index list corresponding to the observations \n    containing more than n outliers according to the Tukey IQR method.\n    \"\"\"\n    outlier_list = []\n    \n    for column in features:\n        # 1st quartile (25%)\n        Q1 = np.percentile(df[column], 25)\n        # 3rd quartile (75%)\n        Q3 = np.percentile(df[column],75)\n        # Interquartile range (IQR)\n        IQR = Q3 - Q1\n        # outlier step\n        outlier_step = 1.5 * IQR\n        # Determining a list of indices of outliers\n        outlier_list_column = df[(df[column] < Q1 - outlier_step) | (df[column] > Q3 + outlier_step )].index\n        # appending the list of outliers \n        outlier_list.extend(outlier_list_column)\n        \n    # selecting observations containing more than x outliers\n    outlier_list = Counter(outlier_list)        \n    multiple_outliers = list( k for k, v in outlier_list.items() if v > min_outliers )\n    \n    # Calculate the number of records below and above lower and above bound value respectively\n    out1 = df[df[column] < Q1 - outlier_step]\n    out2 = df[df[column] > Q3 + outlier_step]\n    \n    print('Total number of deleted outliers is:', out1.shape[0]+out2.shape[0])\n    \n    return multiple_outliers","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:54:19.399052Z","iopub.execute_input":"2023-05-08T08:54:19.400426Z","iopub.status.idle":"2023-05-08T08:54:19.413396Z","shell.execute_reply.started":"2023-05-08T08:54:19.400379Z","shell.execute_reply":"2023-05-08T08:54:19.412131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numeric_columns = (list(raw_df.loc[:, 'Time':'Amount']))\n\niqr_outliers = IQR_method(raw_df,1,numeric_columns)\nraw_df2 = raw_df.drop(iqr_outliers, axis = 0).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:54:19.415042Z","iopub.execute_input":"2023-05-08T08:54:19.415437Z","iopub.status.idle":"2023-05-08T08:54:20.102036Z","shell.execute_reply.started":"2023-05-08T08:54:19.415406Z","shell.execute_reply":"2023-05-08T08:54:20.100848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_df2.Class.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:54:20.103768Z","iopub.execute_input":"2023-05-08T08:54:20.104115Z","iopub.status.idle":"2023-05-08T08:54:20.113956Z","shell.execute_reply.started":"2023-05-08T08:54:20.104083Z","shell.execute_reply":"2023-05-08T08:54:20.112871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"too much missing value, revert to non-removing outlier data","metadata":{}},{"cell_type":"code","source":"del raw_df2","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:54:20.115491Z","iopub.execute_input":"2023-05-08T08:54:20.115829Z","iopub.status.idle":"2023-05-08T08:54:20.125478Z","shell.execute_reply.started":"2023-05-08T08:54:20.115801Z","shell.execute_reply":"2023-05-08T08:54:20.124377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing Data","metadata":{}},{"cell_type":"markdown","source":"### Drop Unused Feature","metadata":{}},{"cell_type":"code","source":"# raw_df.drop('Time',axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:54:20.127366Z","iopub.execute_input":"2023-05-08T08:54:20.128760Z","iopub.status.idle":"2023-05-08T08:54:20.137462Z","shell.execute_reply.started":"2023-05-08T08:54:20.128724Z","shell.execute_reply":"2023-05-08T08:54:20.135974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Split Data","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, StratifiedKFold","metadata":{"execution":{"iopub.status.busy":"2023-05-08T08:54:20.139421Z","iopub.execute_input":"2023-05-08T08:54:20.140254Z","iopub.status.idle":"2023-05-08T08:54:20.223607Z","shell.execute_reply.started":"2023-05-08T08:54:20.140188Z","shell.execute_reply":"2023-05-08T08:54:20.222246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = raw_df.drop('Class', axis=1)\ny = raw_df['Class']\n\nX_train_cv = []\nX_test_cv = []\ny_train_cv = []\ny_test_cv = []\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=1)\nskf = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\nfor i, (train_index, test_index) in enumerate(skf.split(X, y)):\n    X_train_cv.append(X.loc[train_index,:])\n    X_test_cv.append(X.loc[test_index,:])\n    y_train_cv.append(y.loc[train_index])\n    y_test_cv.append(y.loc[test_index])\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T09:00:35.747893Z","iopub.execute_input":"2023-05-08T09:00:35.748322Z","iopub.status.idle":"2023-05-08T09:00:36.160599Z","shell.execute_reply.started":"2023-05-08T09:00:35.748287Z","shell.execute_reply":"2023-05-08T09:00:36.159553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(y_train_cv[0].value_counts())\nprint(y_test_cv[0].value_counts())","metadata":{"execution":{"iopub.status.busy":"2023-05-08T09:00:36.480151Z","iopub.execute_input":"2023-05-08T09:00:36.480934Z","iopub.status.idle":"2023-05-08T09:00:36.494881Z","shell.execute_reply.started":"2023-05-08T09:00:36.480895Z","shell.execute_reply":"2023-05-08T09:00:36.493530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler","metadata":{"execution":{"iopub.status.busy":"2023-05-08T09:00:36.997474Z","iopub.execute_input":"2023-05-08T09:00:36.997844Z","iopub.status.idle":"2023-05-08T09:00:37.003761Z","shell.execute_reply.started":"2023-05-08T09:00:36.997815Z","shell.execute_reply":"2023-05-08T09:00:37.002521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Scale Data","metadata":{}},{"cell_type":"code","source":"scaler = StandardScaler()\n# X_train = pd.DataFrame(scaler.fit_transform(X_train),columns = X_train.columns, index=X_train.index)\n# X_test = pd.DataFrame(scaler.transform(X_test),columns = X_test.columns, index=X_test.index)\n\n# raw_df[[\"Amount\"]] = scaler.fit_transform(raw_df[[\"Amount\"]])\n# raw_df[[\"Time\"]] = scaler.fit_transform(raw_df[[\"Time\"]])\n\n# Transforming the test data\n# X_test[[\"Amount\"]] = scaler.transform(X_test[[\"Amount\"]])\n# X_test[[\"Time\"]] = scaler.transform(X_test[[\"Time\"]])\n\nfor i in range(len(X_train_cv)):\n    X_train_cv[i][[\"Amount\",\"Time\"]] = scaler.fit_transform(X_train_cv[i][[\"Amount\",\"Time\"]])\n#     X_train_cv[i][[\"Time\"]] = scaler.fit_transform(X_train_cv[i][[\"Time\"]])\n\n    # Transforming the test data\n#     X_test_cv[i][[\"Amount\"]] = scaler.transform(X_test_cv[i][[\"Amount\"]])\n    X_test_cv[i][[\"Amount\",\"Time\"]] = scaler.transform(X_test_cv[i][[\"Amount\",\"Time\"]])","metadata":{"execution":{"iopub.status.busy":"2023-05-08T09:00:38.520752Z","iopub.execute_input":"2023-05-08T09:00:38.521133Z","iopub.status.idle":"2023-05-08T09:00:38.859194Z","shell.execute_reply.started":"2023-05-08T09:00:38.521103Z","shell.execute_reply":"2023-05-08T09:00:38.857939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"code","source":"import time\nimport numpy\nfrom sklearn.metrics import classification_report, precision_recall_curve, f1_score, auc, average_precision_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score","metadata":{"execution":{"iopub.status.busy":"2023-05-08T09:00:39.607040Z","iopub.execute_input":"2023-05-08T09:00:39.607785Z","iopub.status.idle":"2023-05-08T09:00:39.614165Z","shell.execute_reply.started":"2023-05-08T09:00:39.607748Z","shell.execute_reply":"2023-05-08T09:00:39.612934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_result = []","metadata":{"execution":{"iopub.status.busy":"2023-05-08T09:00:40.083725Z","iopub.execute_input":"2023-05-08T09:00:40.084121Z","iopub.status.idle":"2023-05-08T09:00:40.089871Z","shell.execute_reply.started":"2023-05-08T09:00:40.084086Z","shell.execute_reply":"2023-05-08T09:00:40.088636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Logistic Regression","metadata":{}},{"cell_type":"code","source":"# %%time\n# logr = LogisticRegression(random_state=1)\n# logr.fit(X_train, y_train)\n# y_preds = logr.predict(X_test)\n# print(classification_report(y_test,y_preds))\n# y_probs = logr.predict_proba(X_test)\n# # keep probabilities for the positive outcome only\n# y_probs = y_probs[:, 1]\n# # predict class values\n# yhat = logr.predict(X_test)\n# lr_precision, lr_recall, _ = precision_recall_curve(y_test, y_probs)\n# lr_f1, lr_auc = f1_score(y_test, yhat), auc(lr_recall, lr_precision)\n# # summarize scores\n# print(f'Logistic: f1 = {round(lr_f1,3)} auc = {round(lr_auc,3)}')\n# # plot the precision-recall curves\n# # no_skill = len(y_test[y_test==1]) / len(y_test)\n# # plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n# plt.plot(lr_recall, lr_precision, label='Logistic')\n# plt.xlabel('Recall')\n# plt.ylabel('Precision')\n# plt.legend()\n# plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T09:00:40.997032Z","iopub.execute_input":"2023-05-08T09:00:40.997423Z","iopub.status.idle":"2023-05-08T09:00:41.002702Z","shell.execute_reply.started":"2023-05-08T09:00:40.997393Z","shell.execute_reply":"2023-05-08T09:00:41.001699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logr = LogisticRegression(random_state=1)\n\naxes = plt.subplot()\ny_real = []\ny_proba = []\nf1_list = []\n# auc_list = []\ntime_list = []\nfor i in range(len(X_train_cv)):\n    print(f'fold #{i+1}')\n    start_time = time.time()\n    logr.fit(X_train_cv[i],y_train_cv[i])\n    elapsed_time = time.time() - start_time\n    print(f'training time {elapsed_time}')\n    time_list.append(elapsed_time)\n    y_probs = logr.predict_proba(X_test_cv[i])\n    # probabilities for the positive outcome only\n    y_probs = y_probs[:, 1]\n    # predict class values\n    yhat = logr.predict(X_test_cv[i])\n    f_score = f1_score(y_test_cv[i], yhat)\n    f1_list.append(f_score)\n    print('f1 score:',f_score)\n    time_list.append(time.time() - start_time)\n    # print(classification_report(y_test_cv[i],yhat))\n    res_precision, res_recall, _ = precision_recall_curve(y_test_cv[i], y_probs)\n    aupr = average_precision_score(y_test_cv[i], y_probs)\n    lab = 'Fold %d AUPR = %.4f' % (i+1, aupr)\n#     model_result.append({'model':'Logistic Regression', 'rec': res_recall, 'prec':res_precision, 'aupr':aupr})\n    axes.step(res_recall, res_precision, label=lab, alpha=0.5)\n    # y_real.append(y_test_cv[i])\n    y_proba.append(y_probs)\n\nprint()\nprint('Avg. Training time:',sum(time_list)/len(time_list))\nprint('Avg. F1-Score Positive class:',sum(f1_list)/len(f1_list))\n\ny_real = numpy.concatenate(y_test_cv)\ny_proba = numpy.concatenate(y_proba)\nprecision, recall, _ = precision_recall_curve(y_real, y_proba)\nlab = 'Overall AUPR = %.4f' % (average_precision_score(y_real, y_proba))\naxes.step(recall, precision, label=lab, lw=2, color='black')\naxes.set_xlabel('Recall')\naxes.set_ylabel('Precision')\naxes.legend(loc='lower left', fontsize='small')\naxes.set_title('Precision-Recall Curve for Positive Class')","metadata":{"execution":{"iopub.status.busy":"2023-05-08T09:00:41.428942Z","iopub.execute_input":"2023-05-08T09:00:41.429389Z","iopub.status.idle":"2023-05-08T09:00:57.768341Z","shell.execute_reply.started":"2023-05-08T09:00:41.429352Z","shell.execute_reply":"2023-05-08T09:00:57.767023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Random Forest","metadata":{}},{"cell_type":"code","source":"# rfc = RandomForestClassifier(random_state=1)\n# rfc.fit(X_train, y_train)\n# y_preds = rfc.predict(X_test)\n# print(classification_report(y_test,y_preds))\n# y_probs = rfc.predict_proba(X_test)\n# # keep probabilities for the positive outcome only\n# y_probs = y_probs[:, 1]\n# # predict class values\n# yhat = rfc.predict(X_test)\n# lr_precision, lr_recall, _ = precision_recall_curve(y_test, y_probs)\n# lr_f1, lr_auc = f1_score(y_test, yhat), auc(lr_recall, lr_precision)\n# # summarize scores\n# print(f'Logistic: f1 = {round(lr_f1,3)} auc = {round(lr_auc,3)}')\n# # plot the precision-recall curves\n# # no_skill = len(y_test[y_test==1]) / len(y_test)\n# # plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n# plt.plot(lr_recall, lr_precision, label='Logistic')\n# plt.xlabel('Recall')\n# plt.ylabel('Precision')\n# plt.legend()\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-08T09:01:08.001092Z","iopub.execute_input":"2023-05-08T09:01:08.001509Z","iopub.status.idle":"2023-05-08T09:01:08.008087Z","shell.execute_reply.started":"2023-05-08T09:01:08.001476Z","shell.execute_reply":"2023-05-08T09:01:08.006741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfc = RandomForestClassifier(n_estimators=100,random_state=1)\n\naxes = plt.subplot()\ny_real = []\ny_proba = []\nf1_list = []\n# auc_list = []\ntime_list = []\nfor i in range(len(X_train_cv)):\n    print(f'fold #{i+1}')\n    start_time = time.time()\n    rfc.fit(X_train_cv[i],y_train_cv[i])\n    elapsed_time = time.time() - start_time\n    print(f'training time {elapsed_time}')\n    time_list.append(elapsed_time)\n    y_probs = rfc.predict_proba(X_test_cv[i])\n    # probabilities for the positive outcome only\n    y_probs = y_probs[:, 1]\n    # predict class values\n    yhat = rfc.predict(X_test_cv[i])\n    f_score = f1_score(y_test_cv[i], yhat)\n    f1_list.append(f_score)\n    print('f1 score:',f_score)\n    time_list.append(time.time() - start_time)\n    # print(classification_report(y_test_cv[i],yhat))\n    res_precision, res_recall, _ = precision_recall_curve(y_test_cv[i], y_probs)\n    aupr = average_precision_score(y_test_cv[i], y_probs)\n    lab = 'Fold %d AUPR = %.4f' % (i+1, aupr)\n#     model_result.append({'model':'Random Forest', 'rec': res_recall, 'prec':res_precision, 'aupr':aupr})\n    axes.step(res_recall, res_precision, label=lab, alpha=0.5)\n    # y_real.append(y_test_cv[i])\n    y_proba.append(y_probs)\n\nprint()\nprint('Avg. Training time:',sum(time_list)/len(time_list))\nprint('Avg. F1-Score Positive class:',sum(f1_list)/len(f1_list))\n\ny_real = numpy.concatenate(y_test_cv)\ny_proba = numpy.concatenate(y_proba)\nprecision, recall, _ = precision_recall_curve(y_real, y_proba)\nlab = 'Overall AUPR = %.4f' % (average_precision_score(y_real, y_proba))\naxes.step(recall, precision, label=lab, lw=2, color='black')\naxes.set_xlabel('Recall')\naxes.set_ylabel('Precision')\naxes.legend(loc='lower left', fontsize='small')\naxes.set_title('Precision-Recall Curve for Positive Class')","metadata":{"execution":{"iopub.status.busy":"2023-05-08T09:02:36.894281Z","iopub.execute_input":"2023-05-08T09:02:36.894745Z","iopub.status.idle":"2023-05-08T09:26:46.666896Z","shell.execute_reply.started":"2023-05-08T09:02:36.894708Z","shell.execute_reply":"2023-05-08T09:26:46.665628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### KNN","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# knn = KNeighborsClassifier(n_neighbors=9)\n# knn.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_preds = knn.predict(X_test)\n# print(classification_report(y_test,y_preds))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_probs = knn.predict_proba(X_test)\n# # keep probabilities for the positive outcome only\n# y_probs = y_probs[:, 1]\n# # predict class values\n# yhat = knn.predict(X_test)\n# lr_precision, lr_recall, _ = precision_recall_curve(y_test, y_probs)\n# lr_f1, lr_auc = f1_score(y_test, yhat), auc(lr_recall, lr_precision)\n# # summarize scores\n# print(f'Logistic: f1 score positive class = {round(lr_f1,3)} auc = {round(lr_auc,3)}')\n# # plot the precision-recall curves\n# # no_skill = len(y_test[y_test==1]) / len(y_test)\n# # plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n# plt.plot(lr_recall, lr_precision, label='RFC')\n# plt.xlabel('Recall')\n# plt.ylabel('Precision')\n# plt.legend()\n# plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=9)\n\naxes = plt.subplot()\ny_real = []\ny_proba = []\nf1_list = []\n# auc_list = []\ntime_list = []\nfor i in range(len(X_train_cv)):\n    print(f'fold #{i+1}')\n    start_time = time.time()\n    knn.fit(X_train_cv[i],y_train_cv[i])\n    elapsed_time = time.time() - start_time\n    print(f'training time {elapsed_time}')\n    time_list.append(elapsed_time)\n    y_probs = knn.predict_proba(X_test_cv[i])\n    # probabilities for the positive outcome only\n    y_probs = y_probs[:, 1]\n    # predict class values\n    yhat = knn.predict(X_test_cv[i])\n    f_score = f1_score(y_test_cv[i], yhat)\n    f1_list.append(f_score)\n    print('f1 score:',f_score)\n    time_list.append(time.time() - start_time)\n    # print(classification_report(y_test_cv[i],yhat))\n    res_precision, res_recall, _ = precision_recall_curve(y_test_cv[i], y_probs)\n    aupr = average_precision_score(y_test_cv[i], y_probs)\n    lab = 'Fold %d AUPR = %.4f' % (i+1, aupr)\n    model_result.append({'model':'Logistic Regression', 'rec': res_recall, 'prec':res_precision, 'aupr':aupr})\n    axes.step(res_recall, res_precision, label=lab, alpha=0.5)\n    # y_real.append(y_test_cv[i])\n    y_proba.append(y_probs)\n\nprint()\nprint('Avg. Training time:',sum(time_list)/len(time_list))\nprint('Avg. F1-Score Positive class:',sum(f1_list)/len(f1_list))\n\ny_real = numpy.concatenate(y_test_cv)\ny_proba = numpy.concatenate(y_proba)\nprecision, recall, _ = precision_recall_curve(y_real, y_proba)\nlab = 'Overall AUPR = %.4f' % (average_precision_score(y_real, y_proba))\naxes.step(recall, precision, label=lab, lw=2, color='black')\naxes.set_xlabel('Recall')\naxes.set_ylabel('Precision')\naxes.legend(loc='lower left', fontsize='small')\naxes.set_title('Precision-Recall Curve for Positive Class')","metadata":{},"execution_count":null,"outputs":[]}]}